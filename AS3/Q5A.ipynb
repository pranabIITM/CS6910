{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AS3_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fetch data from google drive"
      ],
      "metadata": {
        "id": "mxp10zxi0c1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "7_eWPkVKor1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "a2YlTnO30iaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NxkRIsW6qfnx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import pathlib\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import SimpleRNN,LSTM,GRU,Embedding,Dense,Dropout,Input,Concatenate\n",
        "from tensorflow.keras.optimizers import Adam,Nadam\n",
        "from keras import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing"
      ],
      "metadata": {
        "id": "F9g_I5HS0qhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# token mapping\n",
        "def tok_map(data):\n",
        "    source = data['en'].values\n",
        "    target = data['hi'].values\n",
        "    target = '\\t'+target+'\\n'\n",
        "\n",
        "    len_list_s = [len(i) for i in source]\n",
        "    s_max_len = max(len_list_s)\n",
        "\n",
        "    len_list_t = [len(i) for i in target]\n",
        "    t_max_len = max(len_list_t)\n",
        "\n",
        "    # creating tokens of source language\n",
        "    s_tok = set()\n",
        "    for sw in source:\n",
        "        for chr in sw:\n",
        "            s_tok.add(chr)\n",
        "    source_tokens = sorted(list(s_tok))\n",
        "    s_tok_map = dict([(chr,i+1) for i,chr in enumerate(source_tokens)])\n",
        "    s_tok_map[\" \"] = 0\n",
        "\n",
        "    # creating tokens of target language\n",
        "    t_tok = set()\n",
        "    for st in target:\n",
        "        for chr in st:\n",
        "            t_tok.add(chr)\n",
        "    tar_tokens = sorted(list(t_tok))\n",
        "    t_tok_map = dict([(chr,i+1) for i,chr in enumerate(tar_tokens)])\n",
        "    t_tok_map[\" \"] = 0\n",
        "\n",
        "    return source_tokens, s_tok_map, s_max_len, tar_tokens, t_tok_map, t_max_len\n",
        "\n",
        "\n",
        "# load the data given the path\n",
        "def dataLoad(path):\n",
        "    with open(path) as dataFile:\n",
        "        dataset = pd.read_csv(dataFile,sep='\\t',header=None,names=[\"hi\",\"en\",\"\"],skip_blank_lines=True,index_col=None)\n",
        "    dataset = dataset[dataset['hi'].notna()]\n",
        "    dataset = dataset[dataset['en'].notna()]\n",
        "    dataset = dataset[['hi','en']]\n",
        "    return dataset\n",
        "\n",
        "# create inputs for encoder & decoder and target for decoder\n",
        "def dataProcess(data):\n",
        "    src,tar = data['en'].values, data['hi'].values\n",
        "    tar = \"\\t\" + tar + \"\\n\"\n",
        "\n",
        "    slen = len(src)\n",
        "    enc_inp = np.zeros(\n",
        "        (slen,s_max_len), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    tlen = len(tar)\n",
        "    dec_inp = np.zeros(\n",
        "        (tlen,t_max_len), dtype=\"float32\"\n",
        "    )\n",
        "    dec_tar = np.zeros(\n",
        "        (tlen, t_max_len, len(tar_tokens)+1), dtype=\"int\"\n",
        "    )\n",
        "\n",
        "    for i,(sw,tw) in enumerate(zip(src,tar)):\n",
        "        # encoder input\n",
        "        for j,ch in enumerate(sw):\n",
        "            enc_inp[i,j] = s_tok_map[ch]\n",
        "        enc_inp[i,j+1:] = s_tok_map[\" \"]\n",
        "\n",
        "        # decoder input\n",
        "        for j,ch in enumerate(tw):\n",
        "            dec_inp[i,j] = t_tok_map[ch]\n",
        "            if j>0:\n",
        "                dec_tar[i,j-1,t_tok_map[ch]] = 1\n",
        "\n",
        "        # decoder target\n",
        "        dec_inp[i,j+1:] = t_tok_map[\" \"]\n",
        "        dec_tar[i,j:,t_tok_map[\" \"]] = 1\n",
        "        \n",
        "    return enc_inp, dec_inp, dec_tar"
      ],
      "metadata": {
        "id": "DkEdW4NPr2a5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = dataLoad(\"/content/gdrive/MyDrive/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n",
        "source_tokens, s_tok_map, s_max_len, tar_tokens, t_tok_map, t_max_len = tok_map(train)\n",
        "dev = dataLoad(\"/content/gdrive/MyDrive/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n",
        "test = dataLoad(\"/content/gdrive/MyDrive/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\")   "
      ],
      "metadata": {
        "id": "-EiehZ7kWXWK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the training data\n",
        "train_encoder_input, train_decoder_input, train_decoder_target = dataProcess(train)\n",
        "\n",
        "# Process the validation data\n",
        "val_encoder_input, val_decoder_input, val_decoder_target = dataProcess(dev)"
      ],
      "metadata": {
        "id": "81-zvfMcgaJ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uk0ir-VFf3n",
        "outputId": "83cbef5a-4ce3-4786-ddab-8f0edee12aeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              hi          en\n",
            "0             अं          an\n",
            "1        अंकगणित    ankganit\n",
            "2           अंकल       uncle\n",
            "3          अंकुर       ankur\n",
            "4         अंकुरण     ankuran\n",
            "...          ...         ...\n",
            "44199  ह्वेनसांग  hiuentsang\n",
            "44200  ह्वेनसांग  hsuantsang\n",
            "44201  ह्वेनसांग    hyensang\n",
            "44202  ह्वेनसांग    xuanzang\n",
            "44203          ॐ          om\n",
            "\n",
            "[44202 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q9G_NWyTWs1h",
        "outputId": "5b4396d1-7698-4388-e881-aa2ea254e644"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        hi        en\n",
              "0       अं        an\n",
              "1  अंकगणित  ankganit\n",
              "2     अंकल     uncle\n",
              "3    अंकुर     ankur\n",
              "4   अंकुरण   ankuran"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9df21759-97af-4948-9a1c-9073d2af583d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hi</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अं</td>\n",
              "      <td>an</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>अंकगणित</td>\n",
              "      <td>ankganit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>अंकल</td>\n",
              "      <td>uncle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>अंकुर</td>\n",
              "      <td>ankur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंकुरण</td>\n",
              "      <td>ankuran</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9df21759-97af-4948-9a1c-9073d2af583d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9df21759-97af-4948-9a1c-9073d2af583d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9df21759-97af-4948-9a1c-9073d2af583d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention mechanism\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "    def __init__(self, nunits):\n",
        "        super(Attention, self).__init__()\n",
        "        self.V = Dense(1)\n",
        "        self.W1 = Dense(nunits)\n",
        "        self.W2 = Dense(nunits)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # calculate the score\n",
        "        score = self.V(tf.nn.tanh(self.W1((tf.expand_dims(query, 1))) + self.W2(values)))\n",
        "        # attention weights\n",
        "        weights = tf.nn.softmax(score, axis=1)\n",
        "        # context vector\n",
        "        con_vec = weights * values\n",
        "        con_vec = tf.reduce_sum(con_vec, axis=1)\n",
        "        \n",
        "        return con_vec, weights"
      ],
      "metadata": {
        "id": "-kGKuzojWLTD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq2seq model with attention\n",
        "def seq2seqModel(Layer = \"LSTM\", nunits = 32, encl = 2, decl = 2,embds = 32,dense_size=32,dropout=None):\n",
        "    keras.backend.clear_session()\n",
        "    # source_tokens, s_tok_map, s_max_len, tar_tokens, t_tok_map, t_max_len\n",
        "    enc_inps = Input(shape=(None,))\n",
        "    enc_emb = Embedding(input_dim=len(source_tokens)+1, output_dim = embds, mask_zero=True)\n",
        "    encop = enc_emb(enc_inps)\n",
        "\n",
        "    dec_inps = Input(shape=(None,))\n",
        "    dec_emb = Embedding(input_dim = len(tar_tokens)+1,output_dim = embds,mask_zero=True)\n",
        "\n",
        "    att = Attention(nunits)\n",
        "\n",
        "\n",
        "    all = []\n",
        "    concat = Concatenate(axis=-1)\n",
        "\n",
        "    # If the cell type is chosen as LSTM ----------------------------------------------------    \n",
        "    if Layer == \"LSTM\":\n",
        "        encLays = [LSTM(nunits,return_sequences=True) for i in range(encl-1)]\n",
        "        encLast = LSTM(nunits,return_state=True)\n",
        "        encmb = encop\n",
        "        for enLay in encLays:\n",
        "            encmb = enLay(encmb)\n",
        "            if dropout is not None:\n",
        "                encmb = Dropout(dropout)(encmb)\n",
        "            \n",
        "        o,state_h,state_c = encLast(encmb)\n",
        "        encoder_states = [state_h,state_c]\n",
        "        e_states = [encoder_states]*decl\n",
        "        \n",
        "        decoder = [LSTM(nunits,return_sequences=True,return_state=True) for i in range(decl)]\n",
        "        decEmbop = dec_emb(dec_inps)\n",
        "\n",
        "        for i in range(t_max_len):\n",
        "            con_W , _ = att(e_states[0][0],o)\n",
        "            temp = concat([tf.expand_dims(con_W, 1), decEmbop[:,i:i+1,:]])\n",
        "\n",
        "            for i in range(decl):\n",
        "                o,state_h,state_c = decoder[i](temp,initial_state=e_states[i])\n",
        "                e_states[i] = [state_h,state_c]\n",
        "            all.append(o)\n",
        "        \n",
        "\n",
        "    # If the cell type is chosen as GRU ----------------------------------------------------  \n",
        "    elif Layer == \"GRU\":\n",
        "        encLays = [GRU(nunits,return_sequences=True) for i in range(encl-1)]\n",
        "        encLast = GRU(nunits,return_state=True)\n",
        "        encmb = encop\n",
        "        for enLay in encLays:\n",
        "            encmb = enLay(encmb)\n",
        "            if dropout is not None:\n",
        "                encmb = Dropout(dropout)(encmb)\n",
        "            \n",
        "        out = encLast(encmb)\n",
        "        encoder_states = out[1:]\n",
        "\n",
        "        e_states = []\n",
        "        for _ in range(decl):\n",
        "            e_states += encoder_states\n",
        "        \n",
        "        decoder = [GRU(nunits,return_sequences=True,return_state=True) for i in range(decl)]\n",
        "        decEmbop = dec_emb(dec_inps)\n",
        "\n",
        "        for i in range(t_max_len):\n",
        "            con_W , _ = att(e_states[0],out[0])\n",
        "            temp = concat([(tf.expand_dims(con_W, 1)), decEmbop[:,i:i+1,:]])\n",
        "\n",
        "            for i in range(decl):\n",
        "                o,state = decoder[i](temp,initial_state=e_states[i])\n",
        "                e_states[i] = state\n",
        "            all.append(temp)\n",
        "            \n",
        "        \n",
        "    DLayerH = Dense(dense_size, activation='relu')\n",
        "    concat = Concatenate(axis=1)\n",
        "    preact = DLayerH(concat(all))\n",
        "    DL_O = Dense(len(tar_tokens)+1, activation = 'softmax')\n",
        "    act_op = DL_O(preact)\n",
        "    \n",
        "    train_model = Model([enc_inps,dec_inps],act_op)\n",
        "\n",
        "    return train_model"
      ],
      "metadata": {
        "id": "K4ditIkQcbO-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to calculate accuracy\n",
        "def accuracy(true,pred):\n",
        "    mask = tf.cast(tf.math.logical_not(tf.math.equal(true, 0)), dtype='int32')\n",
        "    acc = tf.cast(tf.math.equal(tf.math.argmax(true,axis=2),tf.math.argmax(pred,axis=2)), dtype='int32')\n",
        "    acc = tf.cast(tf.math.equal(tf.reduce_sum(tf.math.multiply(acc,mask),axis=1),tf.reduce_sum(mask,axis=1)), dtype='float32')\n",
        "    return (tf.reduce_mean(acc))"
      ],
      "metadata": {
        "id": "0cEHs03iy48M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {\n",
        "            'values': [10, 15, 20]\n",
        "        },\n",
        "        'lr': {\n",
        "            'values': [1e-2,1e-3]\n",
        "        },\n",
        "        'dense_size': {\n",
        "            'values': [64,128,512]\n",
        "        },\n",
        "        'beam_width': {\n",
        "            'values': [3.0, 5.0, 7.0]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.0,0.2,0.3]\n",
        "        },\n",
        "        'teacher_forcing': {\n",
        "            'values': [0.2, 0.5, 0.9]\n",
        "        },\n",
        "        'nunits': {\n",
        "            'values': [128,256,512]\n",
        "        },\n",
        "        'type_of_layer': {\n",
        "            'values': [\"LSTM\",\"GRU\"]\n",
        "        },\n",
        "        'embed_dim': {\n",
        "            'values': [64,128,256]\n",
        "        },\n",
        "        'enc_dec_layers': {\n",
        "            'values': [1,2,3]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "QeuPmhL74GrZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "FBdQgFLKQxRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSssHQYEQ5BT",
        "outputId": "37028cae-f833-47c9-c2e6-e53b629675a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpratyushdash\u001b[0m (\u001b[33mpandp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def train():\n",
        "    # Default values for hyper-parameters we're going to sweep over\n",
        "    config_defaults = {\n",
        "        'epochs' : 15,\n",
        "        'lr': 1e-2,\n",
        "        'dense_size': 128,\n",
        "        'beam_width': 5.0,\n",
        "        'dropout': 0.,\n",
        "        'teacher_forcing': 0.2,\n",
        "        'nunits': 128,\n",
        "        'type_of_layer': 'GRU',\n",
        "        'embed_dim': 64,\n",
        "        'enc_dec_layers': 1,\n",
        "    }\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init(config=config_defaults,name=\"cs6910-ass3-attn\")\n",
        "    cfg = wandb.config\n",
        "    \n",
        "    wandb.run.name = f'epochs_{cfg.epochs}_nunits_{cfg.nunits}_layer_{cfg.type_of_layer}_edl_{cfg.enc_dec_layers}_emb_{cfg.embed_dim}_ds_{cfg.dense_size}_beam_width_{cfg.beam_width}_do_{cfg.dropout}_lr_{cfg.lr}_teacher_forcing_{cfg.teacher_forcing}'\n",
        "    wandb.run.save()\n",
        "\n",
        "    #Building the model using the parameters provided by the config ---------------------------------------    \n",
        "    train = seq2seqModel(Layer=cfg.type_of_layer, nunits=cfg.nunits, embds=cfg.embed_dim, encl=cfg.enc_dec_layers, decl=cfg.enc_dec_layers, dense_size=cfg.dense_size, dropout=cfg.dropout)\n",
        "    train.compile(optimizer = Adam(learning_rate=cfg.lr),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    print(\"Build Sucessfully\")\n",
        "\n",
        "    # Define early stopping mechanism to reduce extra useless epochs\n",
        "    earlystopping = EarlyStopping(\n",
        "        monitor=\"val_accuracy\", min_delta=0.01, patience=5, verbose=2, mode=\"auto\"\n",
        "    )\n",
        "\n",
        "    # Fit the model after sucessfull model building \n",
        "    train.fit([train_encoder_input,train_decoder_input],train_decoder_target,\n",
        "             batch_size=64,\n",
        "             validation_data = ([val_encoder_input,val_decoder_input],val_decoder_target),\n",
        "             epochs=cfg.epochs,\n",
        "             callbacks = [earlystopping, WandbCallback(monitor='val_accuracy',mode='max')])\n",
        "    print(\"Completed ! \")"
      ],
      "metadata": {
        "id": "JrBJ4lZR4RI-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sweep_id = wandb.sweep(sweep_config,entity=\"pandp\",project = 'CS6910-AS3')"
      ],
      "metadata": {
        "id": "1KiaNu_99rkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, entity = \"pandp\" , project = \"CS6910-AS3\", count=10)"
      ],
      "metadata": {
        "id": "508ZtAE59cyk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}